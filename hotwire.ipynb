{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analysis of the longitudinal velocity profile of a turbulent jet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, we shall analyze hot wire measurements of the velocity of a turbulent jet made in a wind tunnel at ENS de Lyon, by Christophe Baudet and Antoine Naert. A Jupyter notebook can contain the data analysis code (here written in Python), the figures and comments (using the [Markdown](https://daringfireball.net/projects/markdown/syntax) syntax). It can be version-controlled using `git`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the modules we will need:\n",
    "- `numpy` defines the array data structure and many tools to work with arrays. We shall use in particular the `numpy.statistics` submodule.\n",
    "- `matplotlib` is the core module for making plots with Python. The best way to use `matplotlib` is to use the object-oriented API; for our need the central object is the [`matplotlib.pyplot.axes` object](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.axes.html#matplotlib.pyplot.axes). There is also an imperative style API which should look familiar to Matlab users.\n",
    "- `scipy` (optional) contains more advanced tools for scientific computing. We are only importing the submodule dedicated to signal processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find help with Python or the different libraries here:\n",
    "- https://docs.python.org/3/\n",
    "- https://docs.scipy.org/doc/numpy/reference/index.html\n",
    "- https://matplotlib.org/api/pyplot_summary.html\n",
    "- https://docs.scipy.org/doc/scipy/reference/signal.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble: reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first get the data; since it is not too big we can afford keeping everything in memory.\n",
    "We use a single file (using the HDF5 file format) containing 100 independent measurements of velocity $u(t)$ (in $m.s^{-1}$) at 2^20 instants, with a frequency of 23 kHz. The file also contains the sampling times and useful metadata, such as the sampling frequency and the viscosity of air. We read all this information from the file and store it in several variables in RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File('datajet.h5') as datafile:\n",
    "    time = datafile['time'][:]\n",
    "    data = datafile['velocity'][:]\n",
    "    freq = datafile.attrs['sampl_freq']\n",
    "    nu_air = datafile.attrs['viscosity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data array is a matrix containing all the independent measurements. It takes roughly 400MB in RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.*data.size/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nbytes/1024/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1** Plot a few realizations of the signal to get familiar with the data and with `matplotlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. One-point statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we study one-point statistics (i.e. global quantities) of the signal.\n",
    "We first estimate the mean velocity. Immediately after that, we centralize the data by subtracting the mean in each time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2** Compute the mean velocity $U$, the standard deviation $\\sigma$ and the turbulence intensity $I$. Discuss the validity of the Taylor hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on we work with the centered signal $u(x) \\to u(x)-\\langle u \\rangle$.\n",
    "We also define the spatial resolution `dx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data - np.mean(data, axis=-1, keepdims=True)\n",
    "dx = U/freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3** Compute the probability density function for velocity. Compare it to a Gaussian density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4** Compute the mean energy dissipation rate $\\varepsilon$, then the Taylor scale $\\lambda$, the Taylor-scale Reynolds number $R_\\lambda$, and the Kolmogorov scale $\\eta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Two-point statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now move to two-point statistics: energy spectrum and, equivalently, autocorrelation function.\n",
    "First, let us see how to efficiently evaluate the autocorrelation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second-order structure function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a reminder of the definition of the longitudinal autocorrelation function:\n",
    "$$ f(r)=\\langle u(x)u(x+r)\\rangle.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5** Using the basic statistics functions in `numpy` (`np.mean`, `np.var` and `np.correlate`), define a function to evaluate the autocorrelation function of a signal directly from the definition, using the following prototype (write the code in the function and replace `NotImplemented` with the result):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation_naive(x):\n",
    "    \"\"\"\n",
    "    Compute autocorrelation function directly in real space\n",
    "    http://en.wikipedia.org/wiki/Autocorrelation#Estimation\n",
    "    \"\"\"\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that it is slow (using only one velocity measurement). Then remember that the autocorrelation function can be computed from the power spectrum, based on the [Wiener-Khinchin theorem](https://en.wikipedia.org/wiki/Wiener%E2%80%93Khinchin_theorem), and define an alternative function to compute the autocorrelation function of a signal using the Discrete Fourier Transform (`np.fft.rfft`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation_spectral(x):\n",
    "    \"\"\"\n",
    "    Compute autocorrelation function using FFTs\n",
    "    Be careful with the normalization.\n",
    "    \"\"\"\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the estimate of the autocorrelation function for one velocity measurement using the two methods (to gain time, you may do this test using only 1/10 of the time series for the naive method). You can also compare it to the estimate given by the function `scipy.signal.correlate` provided by the `scipy` library.\n",
    "Then compare the performance of the three methods using the iPython magic [`%timeit`](https://ipython.readthedocs.io/en/stable/interactive/magics.html?highlight=timeit#magic-timeit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now estimate the autocorrelation function using all the available data. The following code should be compatible with your `autocorrelation_spectral` function (if not, fix it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrel = np.mean(autocorrelation_spectral(data), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may compare this estimate with the autocorrelation function from individual measurements to check statistical convergence if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6** Estimate the integral scale $L_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that velocity increments are defined by $\\delta u(\\ell) = u(x+\\ell)-u(x)$, and structure functions by $S_n(\\ell)=\\langle \\delta u(\\ell)^n\\rangle$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7** By relating it to the longitudinal velocity autocorrelation function, plot the second-order structure function $S_2$ as a function of scale. Can you identify a range of scales for which it behaves as a power law with exponent $2/3$? with exponent $2$? Annotate the graph by positioning the characteristic length scales $\\eta$, $\\lambda$ and $L_0$. Check that the asympotic value of $S_2(\\ell)$ is $2 U_{\\text{rms}}^2$.\n",
    "To draw this figure, you may need the functions `matplotlib.pyplot.axhline` and `matplotlib.pyplot.axvline`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8** Compute the energy spectrum $E(k)$ and plot it.\n",
    "\n",
    "Again, check that the energy spectrum exhibits a power-law scaling. What is the exponent?\n",
    "Identify the wave numbers associated to the scales $\\eta, \\lambda$ and $L_0$.\n",
    "\n",
    "Compare the scaling ranges of the energy spectrum and the second-order structure function.\n",
    "\n",
    "Tip: The Nyquist frequency is $1/(2dx)$, i.e. the maximum wave number is $\\pi/dx$.\n",
    "The function `np.fft.rfftfreq` returns sample frequencies for the Discrete Fourier Transform, we just need to multiply by $2\\pi$ to get wave numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9** Estimate the Kolmogorov constant $C_K$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third-order structure function: the 4/5 law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the second-order, there is no trick to compute efficiently the higher-order structure functions $S_n(\\ell)$ ($n>2$). Let us first check that the direct computation using increments coincide with the above results for $S_2(\\ell)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10** Using 100 logarithmically spaced increments across the whole range of scales, compute $S_2(\\ell)$ without using the velocity autocorrelation function and compare it with the above result.\n",
    "\n",
    "You might need to use the `np.logspace` function, and to define the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_scale(Lmin, Lmax, nincr):\n",
    "    \"\"\"\n",
    "    Return the indices corresponding to nincr logarthmically spaced increments \n",
    "    between scales Lmin and Lmax.\n",
    "    \"\"\"\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us use the same approach for the higher-order structure functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11** Compute the third order structure function $S_3$ and plot it (you might reuse the function `increment_scale`). Is it in agreement with the $4/5$-law?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: the $4/5$-law states that\n",
    "$$ \\lim_{\\ell \\to 0} \\lim_{\\nu \\to 0} \\lim_{t \\to +\\infty} \\frac{S_3(\\ell)}{\\ell} = -\\frac{4}{5} \\varepsilon.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermittency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12** Using the same method as for $S_3$, compute and plot the higher-order structure functions $S_n(\\ell)$ ($n>3$). Do they exhibit a power-law scaling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13** Now compute and plot the probability density function for the velocity increments $\\delta u (\\ell)$ at various scales $\\ell$. You should actually normalize the velocity increments by using the variable $\\delta u(\\ell)/\\sqrt{S_2(\\ell)}$. Are the velocity increments Gaussian?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14** Plot the scaling exponents $\\zeta(n)$ such that $S_n(\\ell) \\sim \\ell^{\\zeta(n)}$ in the inertial range for $n \\leq 6$. Are the velocity increments self-similar?\n",
    "\n",
    "Comment on the statistical convergence of the high-order moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
